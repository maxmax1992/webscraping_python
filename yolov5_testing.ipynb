{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/maxim/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2021-12-14 torch 1.8.0 CUDA:0 (TITAN RTX, 24217MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 367 layers, 46533693 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cbb9d9c1ce4771a6f77421614a43fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=168949.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414a4c5ca7364c08b66eb396ac24f17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=487438.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>455.170074</td>\n",
       "      <td>6.091631</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>646.452576</td>\n",
       "      <td>0.919255</td>\n",
       "      <td>63</td>\n",
       "      <td>laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.231018</td>\n",
       "      <td>490.013275</td>\n",
       "      <td>563.368652</td>\n",
       "      <td>634.279175</td>\n",
       "      <td>0.696675</td>\n",
       "      <td>63</td>\n",
       "      <td>laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.530380</td>\n",
       "      <td>2.331192</td>\n",
       "      <td>733.524414</td>\n",
       "      <td>510.334686</td>\n",
       "      <td>0.670114</td>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.388454</td>\n",
       "      <td>134.259598</td>\n",
       "      <td>230.648956</td>\n",
       "      <td>331.347443</td>\n",
       "      <td>0.652740</td>\n",
       "      <td>67</td>\n",
       "      <td>cell phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         xmin        ymin         xmax        ymax  confidence  class  \\\n",
       "0  455.170074    6.091631  1080.000000  646.452576    0.919255     63   \n",
       "1    1.231018  490.013275   563.368652  634.279175    0.696675     63   \n",
       "2   41.530380    2.331192   733.524414  510.334686    0.670114      0   \n",
       "3   60.388454  134.259598   230.648956  331.347443    0.652740     67   \n",
       "\n",
       "         name  \n",
       "0      laptop  \n",
       "1      laptop  \n",
       "2      person  \n",
       "3  cell phone  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import os.path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5l')\n",
    "\n",
    "# Images\n",
    "for f in ['zidane.jpg', 'bus.jpg']:\n",
    "    torch.hub.download_url_to_file('https://ultralytics.com/images/' + f, f)  # download 2 images\n",
    "img1 = Image.open('zidane.jpg')  # PIL image\n",
    "img0 = Image.open('11.jpg')\n",
    "img2 = cv2.imread('bus.jpg')[..., ::-1]  # OpenCV image (BGR to RGB)\n",
    "img4 = Image.open('/data_disk_10TB/office_web_images/6133.jpg')\n",
    "imgs = [img1, img0, img2, img4]  # batch of images\n",
    "\n",
    "# Inference\n",
    "results = model(imgs)  # includes NMS\n",
    "# Results\n",
    "# results.print()  \n",
    "results.show() # or .show()\n",
    "\n",
    "results.xyxy[0]  # img1 predictions (tensor)\n",
    "results.pandas().xyxy[3]  # img1 predictions (pandas)\n",
    "#      xmin    ymin    xmax   ymax  confidence  class    name\n",
    "# 0  749.50   43.50  1148.0  704.5    0.874023      0  person\n",
    "# 1  433.50  433.50   517.5  714.5    0.687988     27     tie\n",
    "# 2  114.75  195.75  1095.0  708.0    0.624512      0  person\n",
    "# 3  986.00  304.00  1028.0  420.0    0.286865     27     tie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "imgs = glob('/data_disk_10TB/office_web_images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_person_in_values(xyxy, i):\n",
    "    return 'person' in xyxy[i]['name'].values\n",
    "\n",
    "def get_tgt_path(filepath):\n",
    "    to_replace = filepath.split('/')\n",
    "    to_replace[2] = 'office_web_images_no_humans'\n",
    "    return '/'.join(to_replace)\n",
    "\n",
    "def move_to_folder(source, target):\n",
    "    pass\n",
    "\n",
    "range_i = list(range(len(imgs)))\n",
    "for i in range(0, len(imgs), 5):\n",
    "    process_i = range_i[i:i+5]\n",
    "    images = []\n",
    "    img_names = []\n",
    "    tgt_names = []\n",
    "    for i_curr in process_i:\n",
    "        img_name = imgs[i_curr]\n",
    "#         print(img_name)\n",
    "        tgt_path = get_tgt_path(img_name)\n",
    "        try:\n",
    "            im = Image.open(img_name)\n",
    "            images.append(im)\n",
    "            img_names.append(img_name)\n",
    "            tgt_names.append(tgt_path)\n",
    "        except:\n",
    "            if os.path.exists(img_name):\n",
    "                os.remove(img_name)\n",
    "            \n",
    "        \n",
    "#     images = [img1, img0, img2, img4]  # batch of images\n",
    "    if len(images) > 0:\n",
    "        results = model(images)\n",
    "        xyxy = results.pandas().xyxy  # img1 predictions (pandas)\n",
    "        for j in range(len(images)):\n",
    "            if is_person_in_values(xyxy, j):\n",
    "                os.rename(img_names[j], tgt_names[j])\n",
    "        time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_person_in_values(results.pandas().xyxy, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.cuda' from '/home/maxim/anaconda3/envs/yolov5/lib/python3.7/site-packages/torch/cuda/__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "yolov5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
